---
title: Tag 6 - RDF und SPARQL
date: 2025-01-03
---

### Das echte RDF
Kommt jetzt. Zumindest hatte ich ja das Gefühl, der Abschnitt arbeitet sehr viel eindeutiger mit RDF als der davor. Hinzu kommen laut Beschreibung SPARQL und die DBpedia, was ich nach meinen Erinnerungen durchaus bestätigen kann. Am Rande möchte ich erwähnen, dass wir mittlerweile aus dem Bereich, der mir durch die Arbeit vertraut ist, komplett raus sind. SPARQL ist mir bekannt als etwas, mit dem ich theoretisch eine Datenbank, mit der ich im Beruf arbeiten muss, leichter durchsuchen könnte, dies aber nicht tue und stattdessen auf ein Programm zur Visualisierung angewiesen bin. Allerdings gefällt mir - wenig überraschend - wie praktisch die aktuellen Themen sind, weshalb mir die Map auch keine Sorgen macht.

###### Concept Map zum Thema RDF + SPARQL
![Concept Map](https://raw.githubusercontent.com/piaspios/datenformate/refs/heads/master/assets/images/cmaprdfsparql.png)

### Der Runterschrieb
Zentral in der Map ist RDF, welches in vielen verschiedenen Serialisierungen dargestellt werden kann. Eine der bekanntesten und ältesten ist RDF/XML, die zwar viel unterstützt ist, allerdings für den Menschen sehr unübersichtlich und kompliziert ist. Turtle bildet hier das Gegenteil - ist also menschenlesbar und erlaubt Abkürzungen, dafür ist es aber nicht immer mit allen Tools kompatibel. Zentral in der Darstellung von RDF sind Tripel, die sich jeweils aus einem Subjekt, einem Prädikat, und einem Objekt zusammensetzen. Alle drei Teile des Tripels können als URI dargestellt werden, Objekte auch als Literale.

Um eine größere Menge an RDF-Daten zu durchsuchen, kann man diese Daten mit SPARQL abfragen. Zusätzlich zu der Sprache selbst gibt es das SPARQL Protocol und die Query Results Format, welche in JSON und XML ausgegeben werden. SPARQL hat - natürlich - wie alle Sprachen in diesem Metier eine genaue Syntax, die in der Reihenfolge Präfix, Abfragetyp, Muster, und (optional) Modifikatoren abgebildet wird. Das Präfix definiert die Schemata, die zur Formulierung der Suchanfrage verwendet werden können, das Muster gibt an, welche Kriterien auf die Daten zutreffen müssen und die Modifikation kann verwendet werden, um die Ergebnisanzeige zu steuern.

Es gibt vier Abfragetypen, die in einer SPARQL-Abfrage verwendet werden können - SELECT, ASK, DESCRIBE, CONSTRUCT. Diese Typen sind jeweils dafür da, eine bestimmte Menge bzw. Art von Daten in einer Ergebnistabelle auszugeben (SELECT) oder um die Wahrheit einer Abfrage zu bestimmen (ASK). DESCRIBE wird verwendet, um die gewählten Daten zu beschreiben, wobei dieser Typ nicht besonders stark standardisiert ist und somit unterschiedliche Ergebnisse liefern kann. CONSTRUCT kreiert Tripel aus den abgefragten Daten.

SPARQL kann zum Beispiel verwendet werden, um Abfragen mittels der DBpedia zu stellen, die Daten aus der Wikipedia extrahiert. Somit können komplexe Anfragen gestellt werden, die strukturiert Wikipedia durchsuchen, und eine Antwort im Format RDF ausgeben, die Daten von mehreren Unterseiten kompiliert.

### Alles klar!
Hier ein schönes Problem: Ich find die (Idee der) DBpedia sehr interessant und dachte mir, es wär doch schön, dort eine kurz Abfrage zu starten, und ein paar Ergebniszeilen hier in RDF/XML und Turtle festzuhalten, auch für den direkten Vergleich des Tripelaufbaus. Die DBpedia jedoch ist alles anderes als intuitiv. In der Vorlesung hatten wir [eine Oberfläche](), die einen SPARQL Endpoint für die DNB anbot, was mir sehr viel leichter vorkam. Vielleicht liegt das jedoch nur daran, dass ich schon damit vertraut bin, wie diese Daten - und vor allem ihre URIs - in der Regel aussehen. Beim Recherchieren bin ich dann zusätzlich auf den [Wikidata Endpoint]() getroffen, der extremst freundlich für Nutzende aufgebaut ist und textbasierte Suche nach Arten von Beziehungen und Objekten erlaubt. Bei der DBpedia muss ich gefühlt auf gut Glück eine Seite eines bestimmten Objektes öffnen und hoffen, dass ich darauf Verlinkungen auf die Sorte Beziehung oder Klassifikation finde, nach der ich suche. Nicht so spaßig!

Nach einer Weile rumklicken hatte ich dann aber eine Anfrage, die mir ein Ergebnis lieferte:
```
select distinct ?bib where {
    ?bib rdf:type dbo:Library .
    ?bib dbo:country dbr:Germany .
}
```
Oder einfacher ausgedrückt, liefer mir alles mit dem Wert "Bib", wobei dieser Wert nur Daten enthalten darf, die den Typ "Library" und das Land "Germany" haben. Sprich, Bibliotheken in Deutschland.

Diese Anfrage lieferte mir sage und schreibe 26 Ergebnisse. Ich glaube, mit gutem Schuhwerk und wenn die deutsche Bahn mitspielt, könnte ich locker 26 Bibliotheken allein an einem Tag erreichen. Dieselbe Anfrage bei Wikidata (hier sind es "Instanzen" (P31) von Bibliotheken (Q7075) im Land (P17) Deutschland (Q183), was sich leicht zusammensuchen lässt) spuckt 2303 Ergebnisse aus. Sicherlich ist auch dies nicht die exakte Gesamtzahl aller Bibliotheken in Deutschland, aber es dürfte eine weitaus realistischer Wert sein als "26". Was passiert hier also?

Dass Wikidata und die DBpedia nicht dasselbe sein können oder zumindest nicht dieselben Daten durchsuchen, muss ja eigentlich der Fall sein, denn sonst gäbe es keinen Grund für die Existenz von beiden. Natürlich gibt es redundante Suchsysteme, aber das wäre schon eine Redundanz von sehr großem Umfang. [Das Internet behauptet[(https://www.quora.com/How-is-Wikidata-related-to-Wikipedia-in-a-way-different-from-how-DBpedia-is-related-to-Wikipedia), Wikidata liefert bereits strukturierte Daten an Wikipedia, während die DBpedia sich unstrukturierte Daten aus Wikipedia zieht und versucht, diese zu strukturieren. Das müsste heißen, die DBpedia versucht, genau die Daten, die Autor:innen in Wikipedia eintragen, zu strukturieren. 

| [Zurück zum vorherigen Eintrag](https://piaspios.github.io/datenformate/2024/12/28/tag5.html) | [Zurück zur Homepage](https://piaspios.github.io/datenformate/) | [Weiter zum nächsten Eintrag](URL) |
